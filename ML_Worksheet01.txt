#MACHINE LEARNING WORKSHEET - 1#

ANSWERS:-

1) C

2) C

3) C

4) B

5) C

6) C

7) D

8) A,B

9) A,D

10) C

11) Outliers means the values which are far away from actual values.If Outliers can't be treated beforeand supplied to the model then there are higher chances that model will 
wrongly predict the prediction values.For IQR Rule Lets See the following example
See the interquartile range rule at work with an example. Suppose you have the following set of data: 1, 3, 4, 6, 7, 7, 8, 8, 10, 12, 17. The five-number summary for this data set is minimum = 1, first quartile = 4, median = 7, third quartile = 10 and maximum = 17. You may look at the data and automatically say that 17 is an outlier,
Now Lets Calculate Q3 – Q1 = 10 – 4 = 6
Now multiply your answer by 1.5 to get 1.5 x 6 = 9. Nine less than the first quartile is 4 – 9 = -5. No data is less than this. Nine more than the third quartile is 10 + 9 =19. No data is greater than this. Despite the maximum value being five more than the nearest data point,
 the interquartile range rule shows that it should probably not be considered an outlier for this data set.

12) Bagging and Boosting get N learners by generating additional data in the training stage. N new training data sets are produced by random sampling with replacement from the original set. By sampling with replacement some observations may be repeated in each new training data set.
In the case of Bagging, any element has the same probability to appear in a new data set. However, for Boosting the observations are weighted and therefore some of them will take part in the new sets more often:

13) R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. Whereas correlation explains the strength of the relationship between an independent and dependent variable, 
R-squared explains to what extent the variance of one variable explains the variance of the second variable.
 So, if the R2 of a model is 0.50, then approximately half of the observed variation can be explained by the model's inputs.

14) “Normalizing” a vector most often means dividing by a norm of the vector. It also often refers to rescaling by the minimum and range of the vector, to make all the elements lie between 0 and 1 thus bringing all the values of numeric columns in the dataset to a common scale.
“Standardizing” a vector most often means subtracting a measure of location and dividing by a measure of scale. For example, if the vector contains random values with a Gaussian distribution, you might subtract the mean and divide by the standard deviation, thereby obtaining a “standard normal” random variable with mean 0 and standard deviation 1.

15) Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.
The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.
Advantage :- Reducing a chances of overfitting the model
Dis-advantage :- Time consuming in case of large data

